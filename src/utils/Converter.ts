/**
 * ğŸ¨ å¢å¼ºå‹å¤šæ¨¡æ€è½¬æ¢å™¨
 * OpenAI API ä¸ VS Code LM API ä¹‹é—´çš„é©å‘½æ€§è½¬æ¢
 * âœ¨ å®Œå…¨æ”¯æŒå›¾åƒã€å‡½æ•°å’ŒåŠ¨æ€æ¨¡å‹ï¼
 */

import * as vscode from 'vscode';
import * as fs from 'fs';
import * as path from 'path';
import * as http from 'http';
import * as https from 'https';
import * as net from 'net';
import { 
    EnhancedMessage, 
    ModelCapabilities, 
    EnhancedRequestContext,
    ToolCall
} from '../types/ModelCapabilities';
import { 
    OpenAICompletionResponse, 
    OpenAIStreamResponse, 
    OpenAIModelsResponse,
    OpenAIModel,
    OpenAIToolCall
} from '../types/OpenAI';
import { logger } from './Logger';

interface ToolConversionState {
    pendingToolCallIdsByName: Map<string, string[]>;
}

interface StreamExtractionOptions {
    requiresToolCall?: boolean;
}

export class Converter {

    // LanguageModelDataPart è¿è¡Œæ—¶æ£€æµ‹ç¼“å­˜
    private static _dataPartCtor: ((new (data: Uint8Array, mimeType: string) => any) | null) | undefined = undefined;

    /**
     * è¿è¡Œæ—¶æ£€æµ‹ LanguageModelDataPart æ˜¯å¦å¯ç”¨ï¼ˆæ–°ç‰ˆ VS Code æ‰æœ‰ï¼‰
     */
    private static get DataPartCtor(): (new (data: Uint8Array, mimeType: string) => any) | null {
        if (this._dataPartCtor === undefined) {
            try {
                const ctor = (vscode as any).LanguageModelDataPart;
                this._dataPartCtor = (typeof ctor === 'function') ? ctor : null;
            } catch {
                this._dataPartCtor = null;
            }
            if (this._dataPartCtor) {
                logger.info('LanguageModelDataPart available at runtime â€” binary image support enabled');
            } else {
                logger.info('LanguageModelDataPart not available â€” images will be sent as text descriptions');
            }
        }
        return this._dataPartCtor as (new (data: Uint8Array, mimeType: string) => any) | null;
    }

    /**
     * ğŸ¨ å°†å¢å¼ºæ¶ˆæ¯è½¬æ¢ä¸º VS Code LM API æ ¼å¼
     * âœ¨ æ”¯æŒå›¾åƒå’Œå¤šæ¨¡æ€å†…å®¹ï¼
     */
    public static async convertMessagesToVSCode(
        messages: EnhancedMessage[], 
        selectedModel: ModelCapabilities
    ): Promise<vscode.LanguageModelChatMessage[]> {
        const vsCodeMessages: vscode.LanguageModelChatMessage[] = [];
        const conversionState: ToolConversionState = {
            pendingToolCallIdsByName: new Map()
        };
        
        for (const message of messages) {
            try {
                const vsCodeMessage = await this.convertSingleMessage(message, selectedModel, conversionState);
                if (vsCodeMessage) {
                    vsCodeMessages.push(vsCodeMessage);
                }
            } catch (error) {
                logger.error(`è½¬æ¢æ¶ˆæ¯å¤±è´¥ï¼š`, error as Error, { message });
                // å›é€€åˆ°ä»…æ–‡æœ¬å†…å®¹
                if (typeof message.content === 'string') {
                    vsCodeMessages.push(new vscode.LanguageModelChatMessage(
                        this.mapRoleToVSCode(message.role),
                        this.formatRolePrefix(message.role) + message.content
                    ));
                }
            }
        }
        
        return vsCodeMessages;
    }
    
    /**
     * ğŸ“‹ è½¬æ¢å•ä¸ªå¢å¼ºæ¶ˆæ¯
     */
    private static async convertSingleMessage(
        message: EnhancedMessage, 
        selectedModel: ModelCapabilities,
        conversionState: ToolConversionState
    ): Promise<vscode.LanguageModelChatMessage | null> {
        if (message.role === 'tool' || message.role === 'function') {
            return this.convertToolResultMessage(message, conversionState);
        }

        if (message.role === 'assistant' && (message.tool_calls?.length || message.function_call)) {
            return this.convertAssistantToolCallMessage(message, conversionState);
        }
        
        // å¤„ç†ç®€å•æ–‡æœ¬æ¶ˆæ¯
        if (typeof message.content === 'string') {
            return new vscode.LanguageModelChatMessage(
                this.mapRoleToVSCode(message.role),
                this.formatRolePrefix(message.role) + message.content
            );
        }
        
        // å¤„ç†å¤æ‚çš„å¤šæ¨¡æ€å†…å®¹
        if (Array.isArray(message.content)) {
            return await this.convertMultimodalMessage(message, selectedModel);
        }
        
        return null;
    }

    /**
     * ğŸ› ï¸ è½¬æ¢ assistant çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
     */
    private static convertAssistantToolCallMessage(
        message: EnhancedMessage,
        conversionState: ToolConversionState
    ): vscode.LanguageModelChatMessage {
        const parts: Array<vscode.LanguageModelTextPart | vscode.LanguageModelToolCallPart> = [];
        const textContent = this.extractTextContent(message);

        if (textContent) {
            parts.push(new vscode.LanguageModelTextPart(textContent));
        }

        const toolCalls = message.tool_calls || (message.function_call
            ? [{
                id: this.generateLegacyToolCallId(message.function_call.name),
                type: 'function' as const,
                function: {
                    name: message.function_call.name,
                    arguments: message.function_call.arguments
                }
            }]
            : []);

        for (const toolCall of toolCalls) {
            this.trackPendingToolCall(toolCall.function.name, toolCall.id, conversionState);
            parts.push(new vscode.LanguageModelToolCallPart(
                toolCall.id,
                toolCall.function.name,
                this.parseToolArguments(toolCall.function.arguments)
            ));
        }

        return new vscode.LanguageModelChatMessage(
            vscode.LanguageModelChatMessageRole.Assistant,
            parts
        );
    }

    /**
     * ğŸ› ï¸ è½¬æ¢ tool è§’è‰²ç»“æœæ¶ˆæ¯
     */
    private static convertToolResultMessage(
        message: EnhancedMessage,
        conversionState: ToolConversionState
    ): vscode.LanguageModelChatMessage {
        const callId = message.tool_call_id
            || (message.role === 'function' && message.name
                ? this.consumePendingToolCallId(message.name, conversionState)
                : undefined);
        const text = this.extractToolResultText(message.content);
        const content = [new vscode.LanguageModelTextPart(text || '')];

        if (!callId) {
            logger.warn('å·¥å…·ç»“æœæ¶ˆæ¯ç¼ºå°‘ tool_call_idï¼Œé™çº§ä¸ºæ™®é€šç”¨æˆ·æ¶ˆæ¯', {
                role: message.role,
                name: message.name
            });
            return new vscode.LanguageModelChatMessage(
                vscode.LanguageModelChatMessageRole.User,
                text || ''
            );
        }

        return new vscode.LanguageModelChatMessage(
            vscode.LanguageModelChatMessageRole.User,
            [new vscode.LanguageModelToolResultPart(callId, content)]
        );
    }
    
    /**
     * ğŸ–¼ï¸ è½¬æ¢å¸¦å›¾åƒçš„å¤šæ¨¡æ€æ¶ˆæ¯
     */
    private static async convertMultimodalMessage(
        message: EnhancedMessage,
        selectedModel: ModelCapabilities
    ): Promise<vscode.LanguageModelChatMessage | null> {

        if (!Array.isArray(message.content)) {
            return null;
        }

        const DataPartCtor = this.DataPartCtor;
        const canSendBinary = DataPartCtor !== null && selectedModel.supportsVision;

        // ç±»å‹æ”¾å®½ä¸º any[] å› ä¸º LanguageModelDataPart ä¸åœ¨ @types/vscode å£°æ˜ä¸­
        const contentParts: any[] = [];
        let textBuffer = this.formatRolePrefix(message.role);

        for (const part of message.content) {
            if (part.type === 'text' && part.text) {
                textBuffer += part.text;

            } else if (part.type === 'image_url' && part.image_url) {

                if (!selectedModel.supportsVision) {
                    logger.warn(`æ¨¡å‹ ${selectedModel.id} ä¸æ”¯æŒè§†è§‰ï¼Œè·³è¿‡å›¾åƒ`);
                    textBuffer += '\n[Image skipped: model does not support vision]\n';
                    continue;
                }

                if (canSendBinary) {
                    // å…ˆ flush å·²ç§¯ç´¯çš„æ–‡æœ¬
                    if (textBuffer.trim()) {
                        contentParts.push(new vscode.LanguageModelTextPart(textBuffer));
                        textBuffer = '';
                    }

                    try {
                        const imageData = await this.resolveImageData(part.image_url.url);
                        if (imageData) {
                            // æ£€æŸ¥å¤§å°é™åˆ¶
                            const maxSize = selectedModel.maxImageSize || 3 * 1024 * 1024;
                            if (imageData.data.length > maxSize) {
                                logger.warn(`å›¾ç‰‡è¿‡å¤§ (${imageData.data.length} bytes)ï¼Œè¶…è¿‡æ¨¡å‹é™åˆ¶ ${maxSize} bytes`);
                                textBuffer += `\n[Image skipped: ${(imageData.data.length / 1024 / 1024).toFixed(1)}MB exceeds ${(maxSize / 1024 / 1024).toFixed(1)}MB limit]\n`;
                            } else {
                                const dataPart = new DataPartCtor!(
                                    new Uint8Array(imageData.data),
                                    imageData.mimeType
                                );
                                contentParts.push(dataPart);
                                logger.debug(`Added binary image: ${imageData.mimeType}, ${imageData.data.length} bytes`);
                            }
                        } else {
                            // resolveImageData è¿”å› nullï¼ˆè¿œç¨‹ä¸‹è½½å…³é—­æˆ–è§£æå¤±è´¥ï¼‰
                            const desc = await this.processImageContent(part.image_url.url);
                            textBuffer += `\n[Image: ${desc?.description || part.image_url.url.substring(0, 80)}]\n`;
                        }
                    } catch (error) {
                        logger.warn('å¤„ç†å›¾åƒå¤±è´¥:', error as Error);
                        textBuffer += `\n[Image: failed to process]\n`;
                    }
                } else {
                    // VS Code ç‰ˆæœ¬è¿‡æ—§ï¼Œæ—  LanguageModelDataPart â€” é€€å›æ–‡æœ¬æè¿°
                    try {
                        const desc = await this.processImageContent(part.image_url.url);
                        if (desc) {
                            textBuffer += `\n[Image: ${desc.description}]\n`;
                        } else {
                            textBuffer += `\n[Image: ${part.image_url.url.substring(0, 80)}]\n`;
                        }
                    } catch (error) {
                        logger.warn('å¤„ç†å›¾åƒæè¿°å¤±è´¥:', error as Error);
                        textBuffer += `\n[Image: ${part.image_url.url.substring(0, 80)}]\n`;
                    }
                }
            }
        }

        // flush å‰©ä½™æ–‡æœ¬
        if (textBuffer.trim()) {
            contentParts.push(new vscode.LanguageModelTextPart(textBuffer));
        }

        if (contentParts.length === 0) {
            return null;
        }

        return new vscode.LanguageModelChatMessage(
            this.mapRoleToVSCode(message.role),
            contentParts
        );
    }
    
    /**
     * ğŸ–¼ï¸ å¤„ç†å›¾åƒå†…å®¹ï¼ˆBase64ã€URL æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
     */
    private static async processImageContent(imageUrl: string): Promise<{ description: string; data?: string } | null> {
        try {
            // å¤„ç†ä¸åŒçš„å›¾åƒæº
            if (imageUrl.startsWith('data:image/')) {
                // Base64 ç¼–ç å›¾åƒ
                const [header, data] = imageUrl.split(',');
                const mimeType = header.match(/data:([^;]+)/)?.[1] || 'image/jpeg';
                return {
                    description: `Base64 ${mimeType} image`,
                    data: data
                };
                
            } else if (imageUrl.startsWith('http://') || imageUrl.startsWith('https://')) {
                // URL å›¾åƒ - å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œæˆ‘ä»¬åªè®°å½•å®ƒ
                return {
                    description: `Remote image from ${new URL(imageUrl).hostname}`
                };
                
            } else if (imageUrl.startsWith('file://') || await this.fileExists(imageUrl)) {
                // æœ¬åœ°æ–‡ä»¶
                const filePath = imageUrl.startsWith('file://') ? imageUrl.slice(7) : imageUrl;
                const ext = path.extname(filePath).toLowerCase();
                const supportedFormats = ['.jpg', '.jpeg', '.png', '.gif', '.webp'];
                
                if (supportedFormats.includes(ext)) {
                    try {
                        const stats = await fs.promises.stat(filePath);
                        return {
                            description: `Local ${ext.slice(1)} image (${(stats.size / 1024).toFixed(1)}KB)`
                        };
                    } catch (error) {
                        return {
                            description: `Local ${ext.slice(1)} image (size unknown)`
                        };
                    }
                }
            }
            
            return null;
        } catch (error) {
            logger.error('Error processing image:', error as Error);
            return null;
        }
    }

    // ============================================================
    // å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®è§£æï¼ˆç”¨äº LanguageModelDataPartï¼‰
    // ============================================================

    /**
     * å°†å›¾ç‰‡ URL è§£æä¸ºäºŒè¿›åˆ¶æ•°æ® + MIME ç±»å‹
     * æ”¯æŒï¼šdata: URIã€http/https URLï¼ˆéœ€é…ç½®å¯ç”¨ï¼‰ã€æœ¬åœ°æ–‡ä»¶
     */
    private static async resolveImageData(
        imageUrl: string
    ): Promise<{ data: Buffer; mimeType: string } | null> {
        if (imageUrl.startsWith('data:image/')) {
            return this.resolveBase64Image(imageUrl);
        }

        if (imageUrl.startsWith('http://') || imageUrl.startsWith('https://')) {
            const config = vscode.workspace.getConfiguration('copilot-lmapi');
            const allowRemote = config.get<boolean>('allowRemoteImageDownload', false);
            if (!allowRemote) {
                logger.debug('Remote image download disabled, skipping URL image');
                return null;
            }
            return this.downloadRemoteImage(imageUrl, config);
        }

        if (imageUrl.startsWith('file://') || await this.fileExists(imageUrl)) {
            return this.readLocalImage(imageUrl);
        }

        return null;
    }

    /**
     * è§£æ data: URI ä¸ºäºŒè¿›åˆ¶ Buffer
     */
    private static resolveBase64Image(dataUri: string): { data: Buffer; mimeType: string } | null {
        try {
            const commaIdx = dataUri.indexOf(',');
            if (commaIdx === -1) {
                return null;
            }
            const header = dataUri.substring(0, commaIdx);
            const base64Data = dataUri.substring(commaIdx + 1);
            const mimeType = header.match(/data:([^;]+)/)?.[1] || 'image/jpeg';
            return { data: Buffer.from(base64Data, 'base64'), mimeType };
        } catch (error) {
            logger.error('Failed to decode base64 image:', error as Error);
            return null;
        }
    }

    /**
     * ä¸‹è½½è¿œç¨‹å›¾ç‰‡ï¼ˆå¸¦è¶…æ—¶ã€å¤§å°é™åˆ¶ã€ä¸»æœºç™½åå•ï¼‰
     */
    private static async downloadRemoteImage(
        url: string,
        config: vscode.WorkspaceConfiguration
    ): Promise<{ data: Buffer; mimeType: string } | null> {
        const maxBytes = config.get<number>('maxImageBytes', 3 * 1024 * 1024);
        const timeoutMs = config.get<number>('imageFetchTimeoutMs', 10000);
        const allowedHosts = (config.get<string[]>('allowedImageHosts', []) || [])
            .map((host) => host.toLowerCase());

        try {
            const parsedUrl = new URL(url);
            const hostname = parsedUrl.hostname.toLowerCase();

            if (this.isDisallowedRemoteHost(hostname)) {
                logger.warn(`Blocked remote image host: ${hostname}`);
                return null;
            }

            // ä¸»æœºç™½åå•æ£€æŸ¥
            if (allowedHosts.length > 0 && !allowedHosts.includes(hostname)) {
                logger.warn(`Image host ${hostname} not in allowedImageHosts`);
                return null;
            }

            const get = parsedUrl.protocol === 'https:' ? https.get : http.get;

            return await new Promise<{ data: Buffer; mimeType: string } | null>((resolve) => {
                const req = get(url, { timeout: timeoutMs }, (res) => {
                    const status = res.statusCode || 0;
                    if (status >= 300) {
                        res.resume();
                        resolve(null);
                        return;
                    }

                    const contentType = (res.headers['content-type'] || 'image/jpeg').split(';')[0].trim();
                    if (!contentType.startsWith('image/')) {
                        res.resume();
                        logger.warn(`Remote image has non-image content-type: ${contentType}`);
                        resolve(null);
                        return;
                    }

                    const chunks: Buffer[] = [];
                    let received = 0;

                    res.on('data', (chunk: Buffer) => {
                        received += chunk.length;
                        if (received > maxBytes) {
                            req.destroy();
                            logger.warn(`Remote image exceeds maxImageBytes (${maxBytes})`);
                            resolve(null);
                            return;
                        }
                        chunks.push(chunk);
                    });

                    res.on('end', () => {
                        resolve({ data: Buffer.concat(chunks), mimeType: contentType });
                    });

                    res.on('error', () => resolve(null));
                });

                req.on('timeout', () => {
                    req.destroy();
                    logger.warn(`Remote image fetch timeout (${timeoutMs}ms)`);
                    resolve(null);
                });

                req.on('error', (err) => {
                    logger.warn('Remote image fetch error:', err);
                    resolve(null);
                });
            });
        } catch (error) {
            logger.error('Failed to download remote image:', error as Error);
            return null;
        }
    }

    /**
     * è¯»å–æœ¬åœ°å›¾ç‰‡æ–‡ä»¶
     */
    private static async readLocalImage(imageUrl: string): Promise<{ data: Buffer; mimeType: string } | null> {
        try {
            const filePath = imageUrl.startsWith('file://') ? imageUrl.slice(7) : imageUrl;
            const resolvedPath = path.resolve(filePath);
            if (!this.isPathInWorkspace(resolvedPath)) {
                logger.warn(`Blocked local image path outside workspace: ${resolvedPath}`);
                return null;
            }

            const ext = path.extname(filePath).toLowerCase();

            const mimeMap: Record<string, string> = {
                '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg',
                '.png': 'image/png', '.gif': 'image/gif',
                '.webp': 'image/webp',
            };

            const mimeType = mimeMap[ext];
            if (!mimeType) {
                logger.warn(`Unsupported image extension: ${ext}`);
                return null;
            }

            const config = vscode.workspace.getConfiguration('copilot-lmapi');
            const maxBytes = config.get<number>('maxImageBytes', 3 * 1024 * 1024);
            const stats = await fs.promises.stat(resolvedPath);
            if (stats.size > maxBytes) {
                logger.warn(`Local image exceeds maxImageBytes (${maxBytes}): ${resolvedPath}`);
                return null;
            }

            const data = await fs.promises.readFile(resolvedPath);
            return { data, mimeType };
        } catch (error) {
            logger.error('Failed to read local image:', error as Error);
            return null;
        }
    }

    private static isDisallowedRemoteHost(hostname: string): boolean {
        if (hostname === 'localhost' || hostname === '::1') {
            return true;
        }

        const ipVersion = net.isIP(hostname);
        if (ipVersion === 4) {
            const octets = hostname.split('.').map((part) => Number(part));
            if (octets.length !== 4 || octets.some(Number.isNaN)) {
                return true;
            }
            const [a, b] = octets;
            return (
                a === 10 ||
                a === 127 ||
                a === 0 ||
                (a === 169 && b === 254) ||
                (a === 172 && b >= 16 && b <= 31) ||
                (a === 192 && b === 168)
            );
        }

        if (ipVersion === 6) {
            return hostname.startsWith('fc') || hostname.startsWith('fd') || hostname.startsWith('fe80:');
        }

        return false;
    }

    private static isPathInWorkspace(filePath: string): boolean {
        const folders = vscode.workspace.workspaceFolders;
        if (!folders || folders.length === 0) {
            return false;
        }

        return folders.some((folder) => {
            const workspacePath = path.resolve(folder.uri.fsPath);
            const relative = path.relative(workspacePath, filePath);
            return relative === '' || (!relative.startsWith('..') && !path.isAbsolute(relative));
        });
    }

    /**
     * ğŸ§¾ æå–æ¶ˆæ¯ä¸­çš„æ–‡æœ¬å†…å®¹
     */
    private static extractTextContent(message: EnhancedMessage): string {
        if (typeof message.content === 'string') {
            return this.formatRolePrefix(message.role) + message.content;
        }

        if (!Array.isArray(message.content)) {
            return '';
        }

        const textParts = message.content
            .filter(part => part.type === 'text' && !!part.text)
            .map(part => part.text || '');
        const joined = textParts.join('');
        return joined ? this.formatRolePrefix(message.role) + joined : '';
    }

    /**
     * ğŸ§¾ æå– tool ç»“æœæ–‡æœ¬
     */
    private static extractToolResultText(content: EnhancedMessage['content']): string {
        if (typeof content === 'string') {
            return content;
        }

        if (!Array.isArray(content)) {
            return '';
        }

        return content
            .filter(part => part.type === 'text' && !!part.text)
            .map(part => part.text || '')
            .join('');
    }

    /**
     * ğŸ”„ å°†å·¥å…·å‚æ•°å­—ç¬¦ä¸²è§£æä¸ºå¯¹è±¡
     */
    private static parseToolArguments(rawArguments: string): object {
        try {
            const parsed = JSON.parse(rawArguments);
            if (parsed && typeof parsed === 'object') {
                return parsed;
            }
            return { value: parsed };
        } catch {
            return { __raw: rawArguments };
        }
    }

    private static generateLegacyToolCallId(name: string): string {
        return `call_${name}_${Date.now().toString(36)}`;
    }

    private static trackPendingToolCall(name: string, callId: string, conversionState: ToolConversionState): void {
        const pending = conversionState.pendingToolCallIdsByName.get(name) || [];
        pending.push(callId);
        conversionState.pendingToolCallIdsByName.set(name, pending);
    }

    private static consumePendingToolCallId(name: string, conversionState: ToolConversionState): string | undefined {
        const pending = conversionState.pendingToolCallIdsByName.get(name);
        if (!pending || pending.length === 0) {
            return undefined;
        }
        const callId = pending.shift();
        if (pending.length === 0) {
            conversionState.pendingToolCallIdsByName.delete(name);
        } else {
            conversionState.pendingToolCallIdsByName.set(name, pending);
        }
        return callId;
    }

    /**
     * ğŸ”„ VS Code ToolCallPart -> OpenAI ToolCall
     */
    private static convertVSCodeToolCallPart(part: vscode.LanguageModelToolCallPart): ToolCall {
        return {
            id: part.callId,
            type: 'function',
            function: {
                name: part.name,
                arguments: this.stringifyToolInput(part.input)
            }
        };
    }

    private static convertToolCallToOpenAI(toolCall: ToolCall): OpenAIToolCall {
        return {
            id: toolCall.id,
            type: 'function',
            function: {
                name: toolCall.function.name,
                arguments: toolCall.function.arguments
            }
        };
    }

    private static stringifyToolInput(input: object): string {
        try {
            return JSON.stringify(input);
        } catch {
            return '{}';
        }
    }

    private static estimateToolCallTokens(toolCalls: ToolCall[]): number {
        return toolCalls.reduce((total, call) => {
            return total + this.estimateTokensFallback(call.function.name + call.function.arguments);
        }, 0);
    }
    
    /**
     * ğŸ”„ å°† OpenAI è§’è‰²æ˜ å°„åˆ° VS Code è§’è‰²
     */
    private static mapRoleToVSCode(role: string): vscode.LanguageModelChatMessageRole {
        switch (role) {
            case 'system':
            case 'user':
            case 'tool':
            case 'function':
                return vscode.LanguageModelChatMessageRole.User;
            case 'assistant':
                return vscode.LanguageModelChatMessageRole.Assistant;
            default:
                return vscode.LanguageModelChatMessageRole.User;
        }
    }
    
    /**
     * ğŸ·ï¸ ä¸ºå†…å®¹æ ¼å¼åŒ–è§’è‰²å‰ç¼€
     */
    private static formatRolePrefix(role: string): string {
        switch (role) {
            case 'system':
                return 'System: ';
            case 'assistant':
                return '';
            case 'tool':
                return 'Tool: ';
            case 'user':
            default:
                return '';
        }
    }
    
    /**
     * ğŸ“ åˆ›å»ºå¢å¼ºå®Œæˆå“åº”
     */
    public static createCompletionResponse(
        content: string,
        context: EnhancedRequestContext,
        selectedModel: ModelCapabilities,
        toolCalls: ToolCall[] = [],
        preferLegacyFunctionCall: boolean = false,
        completionTokens?: number
    ): OpenAICompletionResponse {
        const now = Math.floor(Date.now() / 1000);
        const openAIToolCalls = toolCalls.map(call => this.convertToolCallToOpenAI(call));
        const isToolResponse = openAIToolCalls.length > 0;
        const useLegacyFunctionCall = preferLegacyFunctionCall && openAIToolCalls.length === 1;
        const finalCompletionTokens = completionTokens ?? (
            this.estimateTokensFallback(content) + this.estimateToolCallTokens(toolCalls)
        );
        const finishReason = isToolResponse
            ? (useLegacyFunctionCall ? 'function_call' : 'tool_calls')
            : 'stop';
        const messageContent = content.length > 0 ? content : (isToolResponse ? null : '');

        const message: OpenAICompletionResponse['choices'][0]['message'] = {
            role: 'assistant',
            content: messageContent
        };

        if (isToolResponse) {
            if (useLegacyFunctionCall && openAIToolCalls[0]) {
                message.function_call = openAIToolCalls[0].function;
            } else {
                message.tool_calls = openAIToolCalls;
            }
        }
        
        return {
            id: `chatcmpl-${context.requestId}`,
            object: 'chat.completion',
            created: now,
            model: context.model, // ä½¿ç”¨è¯·æ±‚çš„æ¨¡å‹åç§°
            choices: [{
                index: 0,
                message,
                finish_reason: finishReason
            }],
            usage: {
                prompt_tokens: context.estimatedTokens,
                completion_tokens: finalCompletionTokens,
                total_tokens: context.estimatedTokens + finalCompletionTokens
            },
            system_fingerprint: `vs-code-${selectedModel.vendor}-${selectedModel.family}`
        };
    }
    
    /**
     * ğŸŒŠ åˆ›å»ºå¢å¼ºæµå¼å“åº”å—
     */
    public static createStreamChunk(
        context: EnhancedRequestContext,
        selectedModel: ModelCapabilities,
        delta: OpenAIStreamResponse['choices'][0]['delta'],
        finishReason: OpenAIStreamResponse['choices'][0]['finish_reason'] = null
    ): OpenAIStreamResponse {
        const now = Math.floor(Date.now() / 1000);
        
        return {
            id: `chatcmpl-${context.requestId}`,
            object: 'chat.completion.chunk',
            created: now,
            model: context.model, // ä½¿ç”¨è¯·æ±‚çš„æ¨¡å‹åç§°
            choices: [{
                index: 0,
                delta,
                finish_reason: finishReason
            }],
            system_fingerprint: `vs-code-${selectedModel.vendor}-${selectedModel.family}`
        };
    }
    
    /**
     * ğŸ“‹ åˆ›å»ºåŠ¨æ€æ¨¡å‹å“åº”
     */
    public static createModelsResponse(availableModels: ModelCapabilities[]): OpenAIModelsResponse {
        const now = Math.floor(Date.now() / 1000);
        
        const models: OpenAIModel[] = availableModels.map(model => ({
            id: model.id,
            object: 'model',
            created: now,
            owned_by: model.vendor || 'vs-code',
            // æ·»åŠ å…³äºèƒ½åŠ›çš„è‡ªå®šä¹‰å…ƒæ•°æ®
            permission: [{
                id: `perm-${model.id}`,
                object: 'model_permission',
                created: now,
                allow_create_engine: false,
                allow_sampling: true,
                allow_logprobs: false,
                allow_search_indices: false,
                allow_view: true,
                allow_fine_tuning: false,
                organization: model.vendor || 'vs-code',
                is_blocking: false
            }]
        }));
        
        return {
            object: 'list',
            data: models
        };
    }

    private static getResponseChunks(
        response: vscode.LanguageModelChatResponse
    ): AsyncIterable<vscode.LanguageModelTextPart | vscode.LanguageModelToolCallPart | string | unknown> {
        const responseWithFallback = response as vscode.LanguageModelChatResponse & {
            stream?: AsyncIterable<unknown>;
            text?: AsyncIterable<string> | string;
        };

        if (responseWithFallback.stream && typeof responseWithFallback.stream[Symbol.asyncIterator] === 'function') {
            return responseWithFallback.stream;
        }

        const legacyText = responseWithFallback.text;
        if (legacyText && typeof (legacyText as AsyncIterable<string>)[Symbol.asyncIterator] === 'function') {
            return legacyText as AsyncIterable<string>;
        }
        if (typeof legacyText === 'string') {
            const text = legacyText;
            return (async function* () {
                if (text) {
                    yield text;
                }
            })();
        }

        throw new Error('Language model response stream is unavailable');
    }
    
    /**
     * ğŸŒŠ ä»å¸¦æœ‰å¢å¼ºä¸Šä¸‹æ–‡çš„ VS Code LM å“åº”æµä¸­æå–å†…å®¹
     */
    public static async *extractStreamContent(
        response: vscode.LanguageModelChatResponse,
        context: EnhancedRequestContext,
        selectedModel: ModelCapabilities,
        options: StreamExtractionOptions = {}
    ): AsyncGenerator<string> {
        const requiresToolCall = !!options.requiresToolCall;
        let emittedRole = false;
        let hasToolCalls = false;
        let emittedToolCallIndex = 0;
        
        try {
            for await (const chunk of this.getResponseChunks(response)) {
                const delta: OpenAIStreamResponse['choices'][0]['delta'] = {};

                if (!emittedRole) {
                    delta.role = 'assistant';
                    emittedRole = true;
                }

                if (chunk instanceof vscode.LanguageModelTextPart) {
                    if (chunk.value) {
                        delta.content = chunk.value;
                    }
                } else if (chunk instanceof vscode.LanguageModelToolCallPart) {
                    const toolCall = this.convertVSCodeToolCallPart(chunk);
                    hasToolCalls = true;
                    delta.tool_calls = [{
                        index: emittedToolCallIndex,
                        id: toolCall.id,
                        type: 'function',
                        function: {
                            name: toolCall.function.name,
                            arguments: toolCall.function.arguments
                        }
                    }];
                    emittedToolCallIndex++;
                } else if (typeof chunk === 'string' && chunk) {
                    delta.content = chunk;
                }

                if (Object.keys(delta).length > 0) {
                    yield this.createSSEEvent('data', this.createStreamChunk(
                        context,
                        selectedModel,
                        delta
                    ));
                }
            }

            if (!emittedRole) {
                yield this.createSSEEvent('data', this.createStreamChunk(
                    context,
                    selectedModel,
                    { role: 'assistant' }
                ));
            }

            if (requiresToolCall && !hasToolCalls) {
                throw new Error('Model did not produce any tool calls despite required tool mode');
            }

            const finishReason: OpenAIStreamResponse['choices'][0]['finish_reason'] = hasToolCalls
                ? 'tool_calls'
                : 'stop';

            yield this.createSSEEvent('data', this.createStreamChunk(
                context,
                selectedModel,
                {},
                finishReason
            ));
            
            // å‘é€å®Œæˆä¿¡å·
            yield this.createSSEEvent('done');
            
        } catch (error) {
            logger.error('å¢å¼ºæµæå–ä¸­å‡ºé”™', error as Error, {}, context.requestId);
            throw error;
        }
    }
    
    /**
     * ğŸ“ ä» VS Code LM å“åº”ä¸­æ”¶é›†æ‰€æœ‰å†…å®¹
     */
    public static async collectFullResponse(
        response: vscode.LanguageModelChatResponse
    ): Promise<{ content: string; toolCalls: ToolCall[] }> {
        let fullContent = '';
        const toolCalls: ToolCall[] = [];
        
        try {
            for await (const chunk of this.getResponseChunks(response)) {
                if (chunk instanceof vscode.LanguageModelTextPart) {
                    fullContent += chunk.value;
                } else if (chunk instanceof vscode.LanguageModelToolCallPart) {
                    toolCalls.push(this.convertVSCodeToolCallPart(chunk));
                } else if (typeof chunk === 'string') {
                    fullContent += chunk;
                }
            }
        } catch (error) {
            logger.error('æ”¶é›†å¢å¼ºå“åº”æ—¶å‡ºé”™', error as Error);
            throw new Error('æ”¶é›†å“åº”å†…å®¹å¤±è´¥');
        }
        
        return { content: fullContent, toolCalls };
    }

    /**
     * ğŸ“ ä½¿ç”¨å®˜æ–¹ countTokens API è®¡ç®— token æ•°é‡ï¼ˆå¤±è´¥æ—¶é™çº§åˆ°æœ¬åœ°ä¼°ç®—ï¼‰
     */
    public static async countTokensOfficial(
        model: vscode.LanguageModelChat,
        input: string | vscode.LanguageModelChatMessage | vscode.LanguageModelChatMessage[],
        cancellationToken?: vscode.CancellationToken
    ): Promise<number> {
        try {
            if (typeof model.countTokens !== 'function') {
                return this.estimateTokensForInputFallback(input);
            }

            if (typeof input === 'string') {
                return await model.countTokens(input, cancellationToken);
            }

            if (Array.isArray(input)) {
                let total = 0;
                for (const message of input) {
                    total += await model.countTokens(message, cancellationToken);
                }
                return total;
            }

            return await model.countTokens(input, cancellationToken);
        } catch (error) {
            logger.warn('Official countTokens failed, falling back to local estimation', {
                modelId: model.id,
                error: String(error)
            });
            return this.estimateTokensForInputFallback(input);
        }
    }

    private static estimateTokensForInputFallback(
        input: string | vscode.LanguageModelChatMessage | vscode.LanguageModelChatMessage[]
    ): number {
        if (typeof input === 'string') {
            return this.estimateTokensFallback(input);
        }

        if (Array.isArray(input)) {
            return input.reduce((total, message) => total + this.estimateTokensForInputFallback(message), 0);
        }

        const serialized = this.serializeMessageForTokenEstimate(input);
        return this.estimateTokensFallback(serialized);
    }

    private static serializeMessageForTokenEstimate(message: vscode.LanguageModelChatMessage): string {
        const rawMessage = message as vscode.LanguageModelChatMessage & {
            content?: unknown;
            role?: unknown;
            name?: unknown;
        };

        const serializedParts: string[] = [];
        if (typeof rawMessage.role === 'string') {
            serializedParts.push(rawMessage.role);
        }
        if (typeof rawMessage.name === 'string') {
            serializedParts.push(rawMessage.name);
        }

        const content = rawMessage.content;
        if (typeof content === 'string') {
            serializedParts.push(content);
            return serializedParts.join('\n');
        }

        if (Array.isArray(content)) {
            for (const part of content) {
                if (typeof part === 'string') {
                    serializedParts.push(part);
                    continue;
                }

                if (part instanceof vscode.LanguageModelTextPart) {
                    serializedParts.push(part.value);
                    continue;
                }

                if (part instanceof vscode.LanguageModelToolCallPart) {
                    serializedParts.push(part.name, this.stringifyToolInput(part.input));
                    continue;
                }

                try {
                    serializedParts.push(JSON.stringify(part));
                } catch {
                    serializedParts.push(String(part));
                }
            }
            return serializedParts.join('\n');
        }

        try {
            serializedParts.push(JSON.stringify(rawMessage));
        } catch {
            serializedParts.push(String(rawMessage));
        }
        return serializedParts.join('\n');
    }
    
    /**
     * ğŸ”„ åˆ›å»ºæœåŠ¡å™¨å‘é€äº‹ä»¶æ•°æ®
     */
    public static createSSEEvent(type: 'data' | 'done' | 'error', data?: any): string {
        switch (type) {
            case 'data':
                return `data: ${JSON.stringify(data)}\n\n`;
            case 'done':
                return 'data: [DONE]\n\n';
            case 'error':
                return `data: ${JSON.stringify({ error: data })}\n\n`;
            default:
                return '';
        }
    }
    
    /**
     * ğŸ“ˆ å¢å¼ºä»¤ç‰Œä¼°ç®—
     */
    private static estimateTokensFallback(text: string): number {
        // æ›´ç²¾ç»†çš„ä»¤ç‰Œä¼°ç®—
        // è€ƒè™‘ä¸åŒè¯­è¨€å’Œç‰¹æ®Šä»¤ç‰Œ
        const baseTokens = Math.ceil(text.length / 4);
        const specialTokens = (text.match(/[\n\r\t]/g) || []).length;
        return baseTokens + specialTokens;
    }
    
    /**
     * ğŸ¯ åˆ›å»ºå¢å¼ºè½¬æ¢ä¸Šä¸‹æ–‡
     */
    public static createEnhancedContext(
        requestId: string,
        modelId: string,
        isStream: boolean,
        messages: EnhancedMessage[],
        selectedModel?: ModelCapabilities,
        clientIP?: string,
        userAgent?: string
    ): EnhancedRequestContext {
        
        // åˆ†ææ¶ˆæ¯å†…å®¹ä»¥è·å–èƒ½åŠ›
        const hasImages = messages.some(msg => 
            Array.isArray(msg.content) && 
            msg.content.some(part => part.type === 'image_url')
        );
        
        const hasFunctions = messages.some(msg => 
            (msg.tool_calls && msg.tool_calls.length > 0) ||
            !!msg.function_call ||
            !!msg.tool_call_id
        );
        
        // ä¼°ç®—æ€»ä»¤ç‰Œæ•°
        const estimatedTokens = messages.reduce((total, msg) => {
            if (typeof msg.content === 'string') {
                return total + this.estimateTokensFallback(msg.content);
            } else if (msg.content === null) {
                return total;
            } else if (Array.isArray(msg.content)) {
                return total + msg.content.reduce((partTotal, part) => {
                    if (part.type === 'text' && part.text) {
                        return partTotal + this.estimateTokensFallback(part.text);
                    }
                    return partTotal + 100; // å›¾åƒä¼°ç®—
                }, 0);
            }
            return total;
        }, 0);
        
        // ç¡®å®šæ‰€éœ€èƒ½åŠ›
        const requiredCapabilities: string[] = [];
        if (hasImages) {
            requiredCapabilities.push('supportsVision');
        }
        if (hasFunctions) {
            requiredCapabilities.push('supportsTools');
        }
        if (isStream) {
            requiredCapabilities.push('supportsStreaming');
        }
        
        return {
            requestId,
            model: modelId,
            isStream,
            startTime: new Date(),
            clientIP,
            userAgent,
            hasImages,
            hasFunctions,
            requiredCapabilities,
            estimatedTokens,
            selectedModel
        };
    }
    
    /**
     * ğŸ“Š åˆ›å»ºå¸¦æœ‰æ¨¡å‹ä¿¡æ¯çš„å¥åº·æ£€æŸ¥å“åº”
     */
    public static createHealthResponse(serverState: any, modelPool?: any) {
        return {
            status: 'ok',
            timestamp: new Date().toISOString(),
            server: {
                running: serverState.isRunning,
                uptime: serverState.startTime ? Date.now() - serverState.startTime.getTime() : 0,
                requests: serverState.requestCount,
                errors: serverState.errorCount,
                activeConnections: serverState.activeConnections
            },
            models: modelPool ? {
                total: modelPool.primary.length + modelPool.secondary.length + modelPool.fallback.length,
                primary: modelPool.primary.length,
                secondary: modelPool.secondary.length,
                fallback: modelPool.fallback.length,
                unhealthy: modelPool.unhealthy.length,
                supportsVision: modelPool.primary.filter((m: any) => m.supportsVision).length,
                supportsTools: modelPool.primary.filter((m: any) => m.supportsTools).length
            } : undefined
        };
    }
    
    /**
     * ğŸ” å¼‚æ­¥æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
     */
    private static async fileExists(filePath: string): Promise<boolean> {
        try {
            await fs.promises.access(filePath);
            return true;
        } catch {
            return false;
        }
    }

    /**
     * ğŸš€ åˆ›å»º OpenAI æ ¼å¼çš„é”™è¯¯å“åº”
     */
    public static createErrorResponse(
        message: string,
        type: string = 'api_error',
        code?: string,
        param?: string
    ) {
        return {
            error: {
                message,
                type,
                code,
                param
            }
        };
    }
}
